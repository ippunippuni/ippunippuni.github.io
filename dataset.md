---
layout: page
title: Dataset
permalink: /dataset/index.html
---

>

Computational journalism had been much depending on in-house, private data, and only a few researchers benefited from such data. Recently, there have been significant efforts to make valuable datasets publicly accessible for the research community.  We hope that NECO will be the place for researchers to discuss such datasets, including Yahoo News Feed dataset and GDELT dataset, as we introduce below.


[Yahoo News Feed dataset, version 1.0](http://webscope.sandbox.yahoo.com/catalog.php?datatype=r&did=75)  
Yahoo has recently released a massive collection of user interactions on the news feeds of Yahoo services, including Yahoo News.  We appreciate Yahooâ€™s contribution to the research community and hope to see much inspiring works.



[The GDELT Project](http://www.gdeltproject.org/)  
The GDELT project is one of the largest data collection of news.  Supported by Google Ideas, it monitors "the world's broadcast, print, and web news" around the world (see details [GDELT 2.0](http://blog.gdeltproject.org/gdelt-2-0-our-global-world-in-realtime/)). They From February 2015,  GDELT continuously adds experimental features, such as categorizing "all of the news imagery" (see details [Visual GKG](http://blog.gdeltproject.org/announcing-the-new-gdelt-visual-global-knowledge-graph-vgkg/)). 







<!-- 
[The New GDELT Visual Global Knowledge Graph (VGKG)](http://blog.gdeltproject.org/announcing-the-new-gdelt-visual-global-knowledge-graph-vgkg/)

[GDELT 2.0: Our Global World in Realtime](http://blog.gdeltproject.org/gdelt-2-0-our-global-world-in-realtime/)

We encourage you to download GDELT dataset, explore it, learn something interesting about it, and submit a paper about it to NECO 2016.

Good research topics might include...

- link analysis
- social network extraction
- tracing the evolution of news
- blog search and filtering
- psychological, sociological, ethnographic, or personality-based studies
analysis of influence among bloggers
- blog summarization and discourse analysis

But you should feel free to explore any aspect of the data that you feel would be of interest to the community. 



**GDELT project**

The philosophy of computational journalism has been shaping new research direction on journalism.  Research that usually involves survey participants is now being proceeded by using large-scale data. One of the outstanding efforts in this research area is the [GDELT project](http://www.gdeltproject.org), which monitors ``the world's broadcast, print, and web news from nearly every corner of every country in over 100 languages''. GDELT translates all other languages into English through collaboration with Google Ideas, and adds metadata, such as a location where an event happens, to each news article. A vast array of studies from prediction to analysis and comparison with private data have been published in exploring the potential of the dataset.

GDELT begins with monitoring a wide range of international news sources, including AfricaNews, Agence France Presse, Associated Press Online, Associated Press Worldstream, BBC Monitoring, Christian Science Monitor, Facts on File, Foreign Broadcast Information Service, United Press International, and the Washington Post, and now in cooperation with Google, it enlarges the data sources to non-English news media.  Today it tracks news media in over 100 languages from the whole world.
The collected news articles are automatically categorized according to the CAMEO (Conflict and Mediation Event Observations) event coding taxonomy by using the open-source TABARI system\footnote{http://eventdata.parusanalytics.com/software.dir/tabari.html}.  


We collect all compressed dump files for English\footnote{http://data.gdeltproject.org/gdeltv2/masterfilelist.txt (Last access: 5 Jan 2016)} and Translingual\footnote{http://data.gdeltproject.org/gdeltv2/masterfilelist-translation.txt (Last access: 5 Jan 2016)} of ten target days. 

For each day, GDELT releases 4 X 24 X 2 = 192 files (one file every 15 minutes for English and Translingual each). 

 

GDELT provides two types of datasets.  One is called Event Database coded by CAMEO taxonomy since 1979, and the other is Global Knowledge Graph (GKG), an expanded dataset about `every person, organization, company, location, and over 230 themes and emotions from every news report' since 2013.  As Event Database does not include the natural disasters because the standard CAMEO taxonomy does not have the relevant category for them but man-made disasters, we use the GKG dataset to study the news coverage of both the natural disasters and man-made ones. 

The GKG dataset provides various fields to describe the characteristics of each event.  Among them we focus on theme (type) of an event, the number of news articles reporting the event, the number of victims, the type how victim is involved (affect, wound, kill, etc.) the type of victims (students, children, soldiers, etc.), and location where the event happens.  The theme of an event is fine-grained (e.g. natural\_disaster\_flooding or natural\_disaster\_landslide) and can be multiply assigned.  



The GDELT v2.1 dataset is a set of "44 million blog posts" made from February 18 2015 till present. The post includes the text as syndicated, as well as metadata such as the blog's homepage, timestamps, etc. The data is formatted in XML and is further arranged into tiers approximating to some degree search engine ranking. The total size of the dataset is 142 GB uncompressed, (27 GB compressed). 

This dataset spans a number of big news events (the Olympics; both US presidential nominating conventions; the beginnings of the financial crisis; ...) as well as everything else you might expect to find posted to blogs. 


You can download the GDELT dataset by 

The full-list of files available are (here)[http://data.gdeltproject.org/gdeltv2/masterfilelist.txt]. 


When citing this dataset in a paper, please use the following reference: 




Community
We have a mailing list for discussing the datasets at http://groups.google.com/group/icwsm-data. Please join to talk about whatever you're doing with the data. In particular, if you are looking for groups to collaborate with, here's a forum for you. We also have a project at Google Code, http://code.google.com/p/icwsm-data/, where we can host tools and resources that you create to go along with the datasets.  -->
